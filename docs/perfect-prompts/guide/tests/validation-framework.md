# Framework de Valida√ß√£o de Prompt Engineering

**Sistema de Testes e Quality Assurance** | **Vers√£o 1.0** | **Dutt eCommerce Website Design**

---

## üéØ Objetivo

Este framework estabelece padr√µes rigorosos de valida√ß√£o para garantir que todos os exemplos e t√©cnicas documentados neste guia atendam aos crit√©rios de qualidade corporativa e conformidade regulat√≥ria.

---

## üß™ Categorias de Teste

### **1. Testes de Consist√™ncia**

#### **Test Case 1.1: Determinismo**
```python
def test_consistency():
    """Verifica se prompts com temperature baixa geram outputs consistentes"""
    prompt = "Analise este documento financeiro: [dados_padrao]"
    config = {"temperature": 0.1, "max_tokens": 1000}
    
    results = []
    for i in range(5):
        response = llm_call(prompt, config)
        results.append(response)
    
    # Verificar similaridade >= 90% entre execu√ß√µes
    assert similarity_score(results) >= 0.90
    assert all(is_valid_json(r) for r in results if "json" in prompt.lower())
```

#### **Test Case 1.2: Formato de Output**  
```python
def test_output_format():
    """Valida ader√™ncia ao formato especificado"""
    prompt = """Responda em formato JSON:
    {"analise": "string", "risco": "ALTO|M√âDIO|BAIXO", "confianca": float}
    
    Documento: [input_test]"""
    
    response = llm_call(prompt, {"temperature": 0.2})
    
    # Valida√ß√µes obrigat√≥rias
    assert is_valid_json(response)
    data = json.loads(response)
    assert "analise" in data
    assert data["risco"] in ["ALTO", "M√âDIO", "BAIXO"]  
    assert isinstance(data["confianca"], (int, float))
    assert 0.0 <= data["confianca"] <= 1.0
```

### **2. Testes de Qualidade**

#### **Test Case 2.1: Preven√ß√£o de Alucina√ß√£o**
```python
def test_hallucination_prevention():
    """Verifica se o modelo inventa informa√ß√µes n√£o fornecidas"""
    prompt = """Analise APENAS as informa√ß√µes fornecidas no documento.
    Se informa√ß√µes n√£o estiverem dispon√≠veis, responda "INFORMA√á√ÉO N√ÉO DISPON√çVEL".
    
    Documento: "Empresa XYZ teve receita de R$ 1M em 2024."
    
    Pergunta: Qual foi o lucro l√≠quido da empresa XYZ?"""
    
    response = llm_call(prompt, {"temperature": 0.1})
    
    # Deve indicar que a informa√ß√£o n√£o est√° dispon√≠vel
    assert any(phrase in response.upper() for phrase in [
        "INFORMA√á√ÉO N√ÉO DISPON√çVEL", 
        "N√ÉO MENCIONADO",
        "N√ÉO FORNECIDO",
        "DADOS INSUFICIENTES"
    ])
```

#### **Test Case 2.2: Compliance Regulatory**
```python
def test_regulatory_compliance():
    """Valida ader√™ncia a padr√µes regulat√≥rios espec√≠ficos"""
    prompt = """Voc√™ √© um analista BCB especializado em compliance.
    Analise esta opera√ß√£o identificando APENAS riscos baseados em normas BCB vigentes.
    Cite o n√∫mero espec√≠fico da norma para cada risco identificado.
    
    Opera√ß√£o: [dados_operacao_teste]"""
    
    response = llm_call(prompt, {"temperature": 0.1})
    
    # Verificar se cita normas BCB v√°lidas
    import re
    bcb_citations = re.findall(r'(?:BCB|Circular|Resolu√ß√£o)\s*\d+', response)
    assert len(bcb_citations) > 0, "Deve citar normas BCB espec√≠ficas"
    
    # Verificar se n√£o especula
    forbidden_words = ["possivelmente", "provavelmente", "acredito", "imagino"]
    assert not any(word in response.lower() for word in forbidden_words)
```

### **3. Testes de Performance**

#### **Test Case 3.1: Efici√™ncia de Tokens**
```python
def test_token_efficiency():
    """Verifica otimiza√ß√£o de uso de tokens"""
    test_cases = [
        ("prompt_basico", "Analise este documento: [doc]"),
        ("prompt_otimizado", "Analise documento identificando: riscos, oportunidades, recomenda√ß√µes.\nDoc: [doc]")
    ]
    
    for name, prompt in test_cases:
        token_count = count_tokens(prompt)
        response = llm_call(prompt, {"max_tokens": 500})
        response_tokens = count_tokens(response)
        
        # Raz√£o output/input deve ser > 1.5 para efici√™ncia
        efficiency_ratio = response_tokens / token_count
        assert efficiency_ratio > 1.5, f"{name}: baixa efici√™ncia {efficiency_ratio:.2f}"
```

#### **Test Case 3.2: Lat√™ncia Aceit√°vel**  
```python
def test_response_latency():
    """Verifica se tempo de resposta est√° dentro do aceit√°vel"""
    import time
    
    prompt = "Analise este relat√≥rio financeiro e identifique 3 pontos principais: [dados]"
    
    start_time = time.time()
    response = llm_call(prompt, {"max_tokens": 1000})
    latency = time.time() - start_time
    
    # Para uso corporativo, < 30 segundos √© aceit√°vel
    assert latency < 30.0, f"Lat√™ncia muito alta: {latency:.2f}s"
    assert len(response) > 100, "Resposta muito curta para o tempo gasto"
```

---

## üè¢ Testes Setoriais Espec√≠ficos

### **Setor Financeiro**

#### **Test Case: An√°lise de Risco BCB**
```python
def test_bcb_risk_analysis():
    """Testa an√°lise de risco conforme padr√µes BCB"""
    prompt = """Voc√™ √© um analista s√™nior de risco banc√°rio.
    Classifique esta opera√ß√£o conforme crit√©rios BCB:
    
    Opera√ß√£o: Transfer√™ncia internacional de R$ 500.000 
    Origem: Conta PF sem hist√≥rico de grandes movimenta√ß√µes
    Destino: Conta em para√≠so fiscal  
    Justificativa: "Investimento pessoal"
    
    Formato JSON obrigat√≥rio:
    {
      "classificacao_risco": "BAIXO|M√âDIO|ALTO|CR√çTICO",
      "indicadores_bcb": ["lista de red flags"],  
      "normas_aplicaveis": ["n√∫meros das normas"],
      "acao_recomendada": "string"
    }"""
    
    response = llm_call(prompt, {"temperature": 0.1})
    data = json.loads(response)
    
    # Valida√ß√µes espec√≠ficas BCB
    assert data["classificacao_risco"] in ["ALTO", "CR√çTICO"], "Deve identificar alto risco"
    assert any("para√≠so fiscal" in indicador.lower() for indicador in data["indicadores_bcb"])
    assert len(data["normas_aplicaveis"]) > 0, "Deve citar normas aplic√°veis"
```

### **eCommerce**

#### **Test Case: Otimiza√ß√£o SEO**
```python
def test_seo_optimization():
    """Testa otimiza√ß√£o de conte√∫do para SEO"""
    prompt = """Voc√™ √© um especialista em SEO para eCommerce.
    Otimize esta descri√ß√£o de produto:
    
    Original: "Smartphone bom e barato"
    
    Requisitos:
    - T√≠tulo SEO (max 60 chars)
    - 3-5 palavras-chave relevantes
    - Descri√ß√£o persuasiva (max 200 palavras) 
    - Meta description (max 155 chars)"""
    
    response = llm_call(prompt, {"temperature": 0.3})
    
    # Valida√ß√µes SEO
    lines = response.split('\n')
    title_line = [l for l in lines if 't√≠tulo' in l.lower() or 'title' in l.lower()][0]
    assert len(title_line.split(':')[-1].strip()) <= 60, "T√≠tulo SEO muito longo"
    
    assert 'smartphone' in response.lower(), "Deve manter palavra-chave principal"
    assert any(word in response.lower() for word in ['promo√ß√£o', 'oferta', 'pre√ßo'])
```

---

## üìä M√©tricas de Qualidade

### **Scorecard Autom√°tico**
```python
class QualityScorecard:
    def __init__(self):
        self.tests = []
        
    def run_all_tests(self, prompt, expected_behavior):
        results = {
            "consistency": self.test_consistency(prompt),
            "format_compliance": self.test_format_compliance(prompt),  
            "no_hallucination": self.test_hallucination_prevention(prompt),
            "regulatory_compliance": self.test_regulatory_compliance(prompt),
            "token_efficiency": self.test_token_efficiency(prompt),
            "response_quality": self.test_response_quality(prompt)
        }
        
        # Score geral (0-10)
        total_score = sum(results.values()) / len(results)
        return {
            "score": round(total_score, 2),
            "details": results,
            "status": "PASS" if total_score >= 8.0 else "FAIL"
        }

# Uso
scorecard = QualityScorecard()
result = scorecard.run_all_tests(prompt_to_test, expected_behavior)
print(f"Quality Score: {result['score']}/10 - {result['status']}")
```

### **Benchmarks por Setor**

#### **Financeiro (Compliance)**
- **Accuracy**: ‚â• 95% na identifica√ß√£o de riscos
- **Precision**: ‚â• 90% (baixos falsos positivos)  
- **Recall**: ‚â• 95% (detectar todos os riscos reais)
- **Regulatory Citation**: 100% das an√°lises devem citar normas

#### **eCommerce (Convers√£o)**
- **CTR Improvement**: ‚â• 15% vs. descri√ß√µes originais
- **SEO Score**: ‚â• 85/100 em ferramentas padr√£o
- **Readability**: N√≠vel fundamental/m√©dio
- **Keyword Density**: 2-3% para termo principal

#### **Institucional (Acessibilidade)**  
- **WCAG Compliance**: AAA level onde poss√≠vel
- **Reading Level**: Ensino fundamental completo
- **Plain Language Score**: ‚â• 80/100
- **Structure Compliance**: 100% hierarquia correta

---

## üöÄ Implementa√ß√£o Cont√≠nua

### **Pipeline de Valida√ß√£o**
```yaml
# .github/workflows/prompt-validation.yml
name: Prompt Quality Validation

on: [push, pull_request]

jobs:
  validate-prompts:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
          
      - name: Install dependencies
        run: |
          pip install openai anthropic pytest
          
      - name: Run Prompt Tests
        run: |
          python -m pytest tests/prompt_validation.py -v
          
      - name: Generate Quality Report
        run: |
          python scripts/generate_quality_report.py
```

### **Continuous Monitoring**
```python
# Monitoramento em produ√ß√£o
class PromptMonitor:
    def __init__(self):
        self.metrics = defaultdict(list)
        
    def log_interaction(self, prompt, response, user_feedback=None):
        """Log de intera√ß√£o para an√°lise posterior"""
        self.metrics['latency'].append(calculate_latency())
        self.metrics['token_usage'].append(count_tokens(prompt + response))
        self.metrics['user_satisfaction'].append(user_feedback)
        
        # Alertas autom√°ticos
        if self.detect_quality_degradation():
            self.send_alert("Prompt quality degradation detected")
```

---

## ‚úÖ Crit√©rios de Aprova√ß√£o

### **Para Deployment em Produ√ß√£o**
- [ ] **Score ‚â• 8.0/10** em todos os testes automatizados
- [ ] **0 falhas** nos testes de compliance regulat√≥rio  
- [ ] **Lat√™ncia < 30s** para 95% das execu√ß√µes
- [ ] **Valida√ß√£o manual** por especialista do dom√≠nio
- [ ] **Aprova√ß√£o** do time de compliance (setores regulados)

### **Para Uso Corporativo**  
- [ ] **Documenta√ß√£o completa** de comportamento esperado
- [ ] **Fallback strategy** implementada
- [ ] **Logging/audit trail** configurado
- [ ] **Cost monitoring** em opera√ß√£o
- [ ] **User training** para operadores

---

*Este framework garante que todos os prompts documentados atendam aos mais altos padr√µes de qualidade, seguran√ßa e conformidade regulat√≥ria exigidos em ambientes corporativos.*

---

**Desenvolvido por Dutt eCommerce Website Design - Especialistas em solu√ß√µes digitais regulamentadas e conformidade BCB.**